# ðŸ¥ Medical AI Chatbot with BioBERT + Transformer Decoder

A research-grade medical Q&A chatbot combining [BioBERT](https://arxiv.org/abs/1901.08746) embeddings with a custom multi-layer Transformer decoder. Built from scratch in PyTorch and deployed via an interactive Streamlit interface supporting both **Nucleus Sampling** and **Beam Search**.

---

## ðŸš€ Live Demo (Optional)

> **NOTE:** Due to memory constraints on Render's free tier, the live demo is currently unavailable.  
>  
> âœ… You can run this locally in under 5 minutes â€” model weights are auto-downloaded via `setup.py`.

---

## ðŸ“¦ Features

- ðŸ§  **Model:** BioBERT encoder + multi-layer Transformer decoder with causal masking  
- ðŸ” **Training:** AMP, OneCycleLR scheduler, checkpointing, early stopping, label smoothing  
- ðŸŽ›ï¸ **Inference:** Dual-mode decoding (Beam Search, Nucleus Sampling) with adjustable parameters  
- ðŸ§ª **Dataset:** 260K+ real-world doctorâ€“patient Q&A pairs  
- ðŸ–¥ï¸ **Streamlit UI:** Interactive, with chat history, temperature, top-p, and max token settings  

---

## ðŸ§° Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

---

## ðŸ—‚ï¸ File Structure

```
.
â”œâ”€â”€ streamlit_nucleus.py           # Nucleus sampling interface
â”œâ”€â”€ streamlit_beam_search.py      # Beam search interface
â”œâ”€â”€ training.py                   # Full training pipeline
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Downloads and extracts model weights/tokenizer from Google Drive
â”œâ”€â”€ final_model/                  # Populated after setup.py (model weights + tokenizer)
â”œâ”€â”€ checkpoints/                  # Intermediate training checkpoints (optional)
â””â”€â”€ processed_data/               # Dataset folder (not included in repo)
```

---

## ðŸ“¥ How to Run Locally

1. **Download model weights + tokenizer**

```bash
python setup.py
```

This downloads a pre-trained model archive from Google Drive (`Chatbot_Medical_Advice.zip`) and extracts `final_model/`.

2. **Start Streamlit UI**

* Nucleus Sampling (creative generation)

```bash
streamlit run streamlit_nucleus.py
```

* Beam Search (deterministic generation)

```bash
streamlit run streamlit_beam_search.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ðŸ§ª Example Prompts

* What are the symptoms of hypertension?
* How is diabetes diagnosed?
* What causes migraine headaches?
* What are the risk factors for heart disease?

---

## ðŸ§  Model Architecture

```mermaid
graph TD
    A[User Query] --> B[BioBERT Encoder]
    B --> C[Transformer Decoder (Multi-layer)]
    C --> D[Linear + Softmax]
    D --> E[Generated Response]
```

* Encoder: `dmis-lab/biobert-base-cased-v1.1`
* Decoder: 4-layer Transformer, 8 attention heads, causal mask
* Loss: Cross-entropy with label smoothing; padded tokens ignored

---

## ðŸ“ˆ Training Details

* Optimizer: AdamW with OneCycleLR scheduler
* Mixed Precision (AMP) for speed and memory efficiency
* Early stopping and checkpointing enabled
* Final best validation loss: **3.1681** at **epoch 18**
* Training machine: **ASUS ROG Strix G15** (i7 CPU + NVIDIA RTX 3060 GPU)
* Training duration: \~3 weeks on 260K+ samples

---

## ðŸ“¤ Download Model & Full Project

You can download the **entire project** (including trained weights, tokenizer, training scripts, and inference UI) here:

ðŸ“¦ [Google Drive â€“ Chatbot\_Medical\_Advice.zip](https://drive.google.com/file/d/1uZiGAX3XCpnjJnEhwmu1Ds8il0dmEbAt/view?usp=sharing)

After downloading:

```bash
unzip Chatbot_Medical_Advice.zip
cd Chatbot_Medical_Advice
streamlit run streamlit_nucleus.py
```

---

## âš ï¸ Disclaimer

This project and model are intended for **educational and research use only**.
It is **not a substitute for professional medical advice, diagnosis, or treatment**.
Always consult a licensed healthcare provider for medical concerns.

> ðŸ§  **Note:** Due to computational constraints (limited VRAM and training time), the model architecture is intentionally lightweight and may not match production-grade performance. The outputs reflect those limitations.

---
